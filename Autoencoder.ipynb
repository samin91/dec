{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "Autoencoder.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/samin91/dec/blob/master/Autoencoder.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uor9rtVrmUWZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import time\n",
        "import torch\n",
        "import argparse\n",
        "import numpy as np\n",
        "import random\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision.datasets as dset\n",
        "from torch.autograd import Variable\n",
        "import torch.nn.functional as F\n",
        "import torchvision.transforms as transforms\n",
        "from sklearn.cluster import MiniBatchKMeans, KMeans\n",
        "from sklearn.metrics import normalized_mutual_info_score, adjusted_rand_score"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pXF37e3VmUW0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YPOELpmcmUXJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "nmi = normalized_mutual_info_score # for testing the accuracy of k-means on embedded space\n",
        "ari = adjusted_rand_score\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tvk-ts7emUXX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def acc(y_true, y_pred):\n",
        "    \"\"\"\n",
        "    Calculate clustering accuracy. Require scikit-learn installed\n",
        "    # Arguments\n",
        "        y: true labels, numpy.array with shape `(n_samples,)`\n",
        "        y_pred: predicted labels, numpy.array with shape `(n_samples,)`\n",
        "    # Return\n",
        "        accuracy, in [0,1]\n",
        "    \"\"\"\n",
        "    y_true = y_true.astype(np.int64)\n",
        "    assert y_pred.size == y_true.size\n",
        "    D = max(y_pred.max(), y_true.max()) + 1\n",
        "    w = np.zeros((D, D), dtype=np.int64)\n",
        "    for i in range(y_pred.size):\n",
        "        w[y_pred[i], y_true[i]] += 1\n",
        "\n",
        "    from scipy.optimize import linear_sum_assignment\n",
        "    ind = linear_sum_assignment(w.max() - w)\n",
        "    ind = np.asarray(ind)\n",
        "    ind = np.transpose(ind)\n",
        "    return sum([w[i, j] for i, j in ind]) * 1.0 / y_pred.size"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "smDhtFhBmUXf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DEC_AE(nn.Module):\n",
        "    \"\"\"\n",
        "    DEC auto encoder - this class is used to\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, num_classes, num_features):\n",
        "        super(DEC_AE, self).__init__()\n",
        "        self.dropout = nn.Dropout(p=0.1)\n",
        "        self.fc1 = nn.Linear(28 * 28, 500)\n",
        "        self.fc2 = nn.Linear(500, 500)\n",
        "        self.fc3 = nn.Linear(500, 2000)\n",
        "        self.fc4 = nn.Linear(2000, num_features)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.fc_d1 = nn.Linear(500, 28 * 28)\n",
        "        self.fc_d2 = nn.Linear(500, 500)\n",
        "        self.fc_d3 = nn.Linear(2000, 500)\n",
        "        self.fc_d4 = nn.Linear(num_features, 2000)\n",
        "        self.alpha = 1.0\n",
        "        self.clusterCenter = nn.Parameter(torch.zeros(num_classes, num_features))\n",
        "        self.pretrainMode = True\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d) or isinstance(m, nn.Linear):\n",
        "                torch.nn.init.xavier_uniform_(m.weight)\n",
        "\n",
        "    def setPretrain(self, mode):\n",
        "        \"\"\"To set training mode to pretrain or not,\n",
        "        so that it can control to run only the Encoder or Encoder+Decoder\"\"\"\n",
        "        self.pretrainMode = mode\n",
        "\n",
        "    def updateClusterCenter(self, cc):\n",
        "        \"\"\"\n",
        "        To update the cluster center. This is a method for pre-train phase.\n",
        "        When a center is being provided by kmeans, we need to update it so\n",
        "        that it is available for further training\n",
        "        :param cc: the cluster centers to update, size of num_classes x num_features\n",
        "        \"\"\"\n",
        "        self.clusterCenter.data = torch.from_numpy(cc)\n",
        "\n",
        "    def getTDistribution(self, x, clusterCenter):\n",
        "        \"\"\"\n",
        "        student t-distribution, as same as used in t-SNE algorithm.\n",
        "         q_ij = 1/(1+dist(x_i, u_j)^2), then normalize it.\n",
        "\n",
        "         :param x: input data, in this context it is encoder output\n",
        "         :param clusterCenter: the cluster center from kmeans\n",
        "         \"\"\"\n",
        "        xe = torch.unsqueeze(x, 1).cuda() - clusterCenter.cuda()\n",
        "        q = 1.0 / (1.0 + (torch.sum(torch.mul(xe, xe), 2) / self.alpha))\n",
        "        q = q ** (self.alpha + 1.0) / 2.0\n",
        "        q = (q.t() / torch.sum(q, 1)).t()  # due to divison, we need to transpose q\n",
        "        return q\n",
        "\n",
        "    def getDistance(self, x, clusterCenter, alpha=1.0):\n",
        "        \"\"\"\n",
        "        it should minimize the distince to\n",
        "         \"\"\"\n",
        "        if not hasattr(self, 'clusterCenter'):\n",
        "            self.clusterCenter = nn.Parameter(torch.zeros(num_classes, num_classes))\n",
        "        xe = torch.unsqueeze(x, 1).cuda() - clusterCenter.cuda()\n",
        "        # need to sum up all the point to the same center - axis 1\n",
        "        d = torch.sum(torch.mul(xe, xe), 2)\n",
        "        return d\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(-1, 1 * 28 * 28)\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.fc2(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.fc3(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.fc4(x)\n",
        "        x_e = x\n",
        "\n",
        "        # if not in pre_train mode, we need encoder and t distribution output\n",
        "        if self.pretrainMode is False:\n",
        "            return x, self.getTDistribution(x, self.clusterCenter), self.getDistance(x_e, self.clusterCenter), F.softmax(x_e, dim=1)\n",
        "\n",
        "        # encoder is done, followed by decoder\n",
        "        x = self.fc_d4(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.fc_d3(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.fc_d2(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.fc_d1(x)\n",
        "        x_de = x.view(-1, 1, 28, 28)\n",
        "        return x_e, x_de\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0QC9Q97NmUXs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DEC:\n",
        "    \"\"\"The class for controlling the training process of DEC\"\"\"\n",
        "\n",
        "    def __init__(self, n_clusters, n_features, alpha=1.0):\n",
        "        self.n_clusters = n_clusters\n",
        "        self.n_features = n_features\n",
        "        self.alpha = alpha\n",
        "\n",
        "    @staticmethod\n",
        "    def target_distribution(q):\n",
        "        weight = (q ** 2) / q.sum(0)\n",
        "        # print('q',q)\n",
        "        return Variable((weight.t() / weight.sum(1)).t().data, requires_grad=True)\n",
        "\n",
        "    def logAccuracy(self, pred, label):\n",
        "        print(' ' * 8 + '|==>  acc: %.4f,  nmi: %.4f  <==|'\n",
        "              % (acc(label, pred), nmi(label, pred)))\n",
        "\n",
        "    @staticmethod\n",
        "    def kld(q, p):\n",
        "        return torch.sum(p * torch.log(p / q), dim=-1)\n",
        "\n",
        "    @staticmethod\n",
        "    def cross_entropy(q, p):\n",
        "        return torch.sum(torch.sum(p * torch.log(1 / (q + 1e-7)), dim=-1))\n",
        "\n",
        "    @staticmethod\n",
        "    def depict_q(p):\n",
        "        q1 = p / torch.sqrt(torch.sum(p, dim=0))\n",
        "        qik = q1 / q1.sum()\n",
        "        return qik\n",
        "\n",
        "    @staticmethod\n",
        "    def distincePerClusterCenter(dist):\n",
        "        totalDist = torch.sum(torch.sum(dist, dim=0) / (torch.max(dist) * dist.size(1)))\n",
        "        return totalDist\n",
        "\n",
        "    def validateOnCompleteTestData(self, test_loader, model):\n",
        "        model.eval()\n",
        "        to_eval = np.array([model(d[0].cuda())[0].data.cpu().numpy() for i, d in enumerate(test_loader)])\n",
        "        true_labels = np.array([d[1].cpu().numpy() for i, d in enumerate(test_loader)])\n",
        "        to_eval = np.reshape(to_eval, (to_eval.shape[0] * to_eval.shape[1], to_eval.shape[2]))\n",
        "        true_labels = np.reshape(true_labels, true_labels.shape[0] * true_labels.shape[1])\n",
        "        km = KMeans(n_clusters=len(np.unique(true_labels)), n_init=20, n_jobs=4)\n",
        "        y_pred = km.fit_predict(to_eval)\n",
        "        print(' ' * 8 + '|==>  acc: %.4f,  nmi: %.4f  <==|'\n",
        "              % (acc(true_labels, y_pred), nmi(true_labels, y_pred)))\n",
        "        currentAcc = acc(true_labels, y_pred)\n",
        "        return currentAcc\n",
        "\n",
        "    def pretrain(self, train_loader, test_loader, epochs):\n",
        "        dec_ae = DEC_AE(self.n_clusters, self.n_features).cuda()  # auto encoder\n",
        "        mse_loss = nn.MSELoss()# is not used?\n",
        "        optimizer = optim.SGD(dec_ae.parameters(), lr=1, momentum=0.9)\n",
        "        best_acc = 0.0\n",
        "\n",
        "        for epoch in range(epochs):\n",
        "            dec_ae.train()\n",
        "            running_loss = 0.0\n",
        "            for i, data in enumerate(train_loader):\n",
        "                x, label = data\n",
        "                x, label = Variable(x).cuda(), Variable(label).cuda()\n",
        "                optimizer.zero_grad()\n",
        "                x_ae, x_de = dec_ae(x)\n",
        "                loss = F.mse_loss(x_de, x, reduce=True)\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "                # x_eval = x.data.cpu().numpy()\n",
        "                # label_eval = label.data.cpu().numpy()\n",
        "                running_loss += loss.data.cpu().numpy()\n",
        "                if i % 100 == 99:  # print every 100 mini-batches\n",
        "                    print('[%d, %5d] loss: %.7f' %\n",
        "                          (epoch + 1, i + 1, running_loss / 100))\n",
        "                    running_loss = 0.0\n",
        "\n",
        "            # now we evaluate the accuracy with AE\n",
        "            dec_ae.eval()\n",
        "            currentAcc = self.validateOnCompleteTestData(test_loader, dec_ae)\n",
        "\n",
        "            if currentAcc > best_acc:\n",
        "                torch.save(dec_ae, 'bestModel'.format(best_acc))\n",
        "                best_acc = currentAcc\n",
        "\n",
        "    def clustering(self, mbk, x, model):\n",
        "        model.eval()\n",
        "        y_pred_ae, _, _, _ = model(x)# what is this?\n",
        "        y_pred_ae = y_pred_ae.data.cpu().numpy()\n",
        "        y_pred = mbk.partial_fit(y_pred_ae)  # seems we can only get a centre from batch\n",
        "        self.cluster_centers = mbk.cluster_centers_  # keep the cluster centers\n",
        "        model.updateClusterCenter(self.cluster_centers)\n",
        "\n",
        "    def train(self, train_loader, test_loader, epochs):# I am supposed to add my bit here\n",
        "        \"\"\"This method will start training for DEC cluster\"\"\"\n",
        "        ct = time.time()\n",
        "        model = torch.load(\"bestModel\").cuda()\n",
        "        model.setPretrain(False)\n",
        "        # optimizer = optim.SGD([{'params': model.parameters()},], lr=0.01, momentum=0.9)\n",
        "        # params(iterable)–iterable of parameters to optimize or dicts defining parameter groups\n",
        "        optimizer = optim.SGD([{'params': model.parameters()}], lr=0.01, momentum=0.9)\n",
        "        print('Initializing cluster center with pre-trained weights')\n",
        "        mbk = MiniBatchKMeans(n_clusters=self.n_clusters, n_init=20, batch_size=batch_size)\n",
        "        got_cluster_center = False\n",
        "\n",
        "        for epoch in range(epochs):\n",
        "\n",
        "            for i, data in enumerate(train_loader):\n",
        "                x, label = data\n",
        "                x = Variable(x).cuda()\n",
        "                optimizer.zero_grad()\n",
        "                # step 1 - get cluster center from batch\n",
        "                # here we are using minibatch kmeans to be able to cope with larger dataset.\n",
        "\n",
        "                if not got_cluster_center:\n",
        "                    self.clustering(mbk, x, model)# x is 100 images\n",
        "                    if epoch > 1:# what is happening here?\n",
        "                        got_cluster_center = True\n",
        "                else:\n",
        "                    model.train()\n",
        "                    # now we start training with acquired cluster center\n",
        "                    feature_pred, q, dist, clssfied = model(x)\n",
        "                    d = self.distincePerClusterCenter(dist)\n",
        "                    qik = self.depict_q(clssfied)\n",
        "                    loss1 = self.cross_entropy(clssfied, qik)\n",
        "                    loss = d + loss1\n",
        "                    loss.backward()\n",
        "                    optimizer.step()\n",
        "\n",
        "            currentAcc = self.validateOnCompleteTestData(test_loader, model)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zJqS96bpmUX5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "14cd66a3-ad8a-4c3f-9f1f-fed24de73e40"
      },
      "source": [
        "use_cuda = torch.cuda.is_available()\n",
        "use_cuda"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UHTDABrAmUX_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "root = './data'\n",
        "if not os.path.exists(root):\n",
        "    os.mkdir(root)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e9xa06e4mUYJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#random.seed(7)\n",
        "\n",
        "#parser = argparse.ArgumentParser(description='train', formatter_class=argparse.ArgumentDefaultsHelpFormatter)\n",
        "#parser.add_argument('--batch_size', default=100, type=int)\n",
        "#parser.add_argument('--pretrain_epochs', default=1, type=int)\n",
        "#parser.add_argument('--train_epochs', default=1, type=int)\n",
        "#args = parser.parse_args()"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gui3tKSgmUYT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 100\n",
        "pretrain_epochs = 200\n",
        "train_epochs = 200"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "68v0RdxUmUYc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "8db9a280-bc2e-47f9-adf5-de1e9c6b940b"
      },
      "source": [
        "trans = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (1.0,))])\n",
        "\n",
        "# if not exist, download mnist dataset\n",
        "train_set = dset.MNIST(root=root, train=True, transform=trans, download=True)\n",
        "test_set = dset.MNIST(root=root, train=False, transform=trans, download=True)\n",
        "batch_size = batch_size\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    dataset=train_set,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "    dataset=test_set,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=False)\n",
        "\n",
        "dec = DEC(10, 10)\n",
        "if pretrain_epochs > 0:\n",
        "    dec.pretrain(train_loader, test_loader, pretrain_epochs)\n",
        "\n",
        "#dec.train(train_loader, test_loader, train_epochs)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1,   100] loss: 0.0783596\n",
            "[1,   200] loss: 0.0595040\n",
            "[1,   300] loss: 0.0495953\n",
            "[1,   400] loss: 0.0411988\n",
            "[1,   500] loss: 0.0369249\n",
            "[1,   600] loss: 0.0334998\n",
            "        |==>  acc: 0.4885,  nmi: 0.4780  <==|\n",
            "[2,   100] loss: 0.0319182\n",
            "[2,   200] loss: 0.0306892\n",
            "[2,   300] loss: 0.0295749\n",
            "[2,   400] loss: 0.0286883\n",
            "[2,   500] loss: 0.0278499\n",
            "[2,   600] loss: 0.0273086\n",
            "        |==>  acc: 0.5439,  nmi: 0.5135  <==|\n",
            "[3,   100] loss: 0.0265736\n",
            "[3,   200] loss: 0.0261653\n",
            "[3,   300] loss: 0.0253947\n",
            "[3,   400] loss: 0.0250755\n",
            "[3,   500] loss: 0.0247094\n",
            "[3,   600] loss: 0.0244140\n",
            "        |==>  acc: 0.5969,  nmi: 0.5466  <==|\n",
            "[4,   100] loss: 0.0237979\n",
            "[4,   200] loss: 0.0238279\n",
            "[4,   300] loss: 0.0233903\n",
            "[4,   400] loss: 0.0231847\n",
            "[4,   500] loss: 0.0229326\n",
            "[4,   600] loss: 0.0228375\n",
            "        |==>  acc: 0.6253,  nmi: 0.5705  <==|\n",
            "[5,   100] loss: 0.0226164\n",
            "[5,   200] loss: 0.0220662\n",
            "[5,   300] loss: 0.0218553\n",
            "[5,   400] loss: 0.0219071\n",
            "[5,   500] loss: 0.0218748\n",
            "[5,   600] loss: 0.0216301\n",
            "        |==>  acc: 0.6278,  nmi: 0.5783  <==|\n",
            "[6,   100] loss: 0.0212612\n",
            "[6,   200] loss: 0.0212248\n",
            "[6,   300] loss: 0.0209340\n",
            "[6,   400] loss: 0.0207951\n",
            "[6,   500] loss: 0.0207775\n",
            "[6,   600] loss: 0.0207394\n",
            "        |==>  acc: 0.6378,  nmi: 0.5867  <==|\n",
            "[7,   100] loss: 0.0204479\n",
            "[7,   200] loss: 0.0204797\n",
            "[7,   300] loss: 0.0199984\n",
            "[7,   400] loss: 0.0200254\n",
            "[7,   500] loss: 0.0200249\n",
            "[7,   600] loss: 0.0197741\n",
            "        |==>  acc: 0.6534,  nmi: 0.5883  <==|\n",
            "[8,   100] loss: 0.0197253\n",
            "[8,   200] loss: 0.0195290\n",
            "[8,   300] loss: 0.0195500\n",
            "[8,   400] loss: 0.0194504\n",
            "[8,   500] loss: 0.0191692\n",
            "[8,   600] loss: 0.0192848\n",
            "        |==>  acc: 0.6715,  nmi: 0.6099  <==|\n",
            "[9,   100] loss: 0.0190939\n",
            "[9,   200] loss: 0.0190864\n",
            "[9,   300] loss: 0.0189975\n",
            "[9,   400] loss: 0.0188128\n",
            "[9,   500] loss: 0.0187172\n",
            "[9,   600] loss: 0.0187009\n",
            "        |==>  acc: 0.6257,  nmi: 0.6038  <==|\n",
            "[10,   100] loss: 0.0184751\n",
            "[10,   200] loss: 0.0185691\n",
            "[10,   300] loss: 0.0185527\n",
            "[10,   400] loss: 0.0182775\n",
            "[10,   500] loss: 0.0181785\n",
            "[10,   600] loss: 0.0183471\n",
            "        |==>  acc: 0.6609,  nmi: 0.6046  <==|\n",
            "[11,   100] loss: 0.0182648\n",
            "[11,   200] loss: 0.0180933\n",
            "[11,   300] loss: 0.0179113\n",
            "[11,   400] loss: 0.0178934\n",
            "[11,   500] loss: 0.0178934\n",
            "[11,   600] loss: 0.0178156\n",
            "        |==>  acc: 0.6443,  nmi: 0.6223  <==|\n",
            "[12,   100] loss: 0.0177552\n",
            "[12,   200] loss: 0.0176206\n",
            "[12,   300] loss: 0.0176004\n",
            "[12,   400] loss: 0.0177168\n",
            "[12,   500] loss: 0.0174735\n",
            "[12,   600] loss: 0.0174310\n",
            "        |==>  acc: 0.6493,  nmi: 0.6313  <==|\n",
            "[13,   100] loss: 0.0173855\n",
            "[13,   200] loss: 0.0174337\n",
            "[13,   300] loss: 0.0172788\n",
            "[13,   400] loss: 0.0171823\n",
            "[13,   500] loss: 0.0172429\n",
            "[13,   600] loss: 0.0170613\n",
            "        |==>  acc: 0.6877,  nmi: 0.6307  <==|\n",
            "[14,   100] loss: 0.0169157\n",
            "[14,   200] loss: 0.0170336\n",
            "[14,   300] loss: 0.0170930\n",
            "[14,   400] loss: 0.0168565\n",
            "[14,   500] loss: 0.0169828\n",
            "[14,   600] loss: 0.0168649\n",
            "        |==>  acc: 0.7015,  nmi: 0.6468  <==|\n",
            "[15,   100] loss: 0.0167628\n",
            "[15,   200] loss: 0.0167527\n",
            "[15,   300] loss: 0.0167384\n",
            "[15,   400] loss: 0.0166786\n",
            "[15,   500] loss: 0.0166115\n",
            "[15,   600] loss: 0.0165727\n",
            "        |==>  acc: 0.6918,  nmi: 0.6363  <==|\n",
            "[16,   100] loss: 0.0164480\n",
            "[16,   200] loss: 0.0163710\n",
            "[16,   300] loss: 0.0164645\n",
            "[16,   400] loss: 0.0164055\n",
            "[16,   500] loss: 0.0165809\n",
            "[16,   600] loss: 0.0163452\n",
            "        |==>  acc: 0.6931,  nmi: 0.6372  <==|\n",
            "[17,   100] loss: 0.0163166\n",
            "[17,   200] loss: 0.0162177\n",
            "[17,   300] loss: 0.0161348\n",
            "[17,   400] loss: 0.0162180\n",
            "[17,   500] loss: 0.0163710\n",
            "[17,   600] loss: 0.0159365\n",
            "        |==>  acc: 0.7512,  nmi: 0.6718  <==|\n",
            "[18,   100] loss: 0.0159730\n",
            "[18,   200] loss: 0.0159972\n",
            "[18,   300] loss: 0.0161011\n",
            "[18,   400] loss: 0.0160396\n",
            "[18,   500] loss: 0.0159036\n",
            "[18,   600] loss: 0.0158277\n",
            "        |==>  acc: 0.6999,  nmi: 0.6508  <==|\n",
            "[19,   100] loss: 0.0156326\n",
            "[19,   200] loss: 0.0158811\n",
            "[19,   300] loss: 0.0156749\n",
            "[19,   400] loss: 0.0158472\n",
            "[19,   500] loss: 0.0159318\n",
            "[19,   600] loss: 0.0156984\n",
            "        |==>  acc: 0.7036,  nmi: 0.6536  <==|\n",
            "[20,   100] loss: 0.0155182\n",
            "[20,   200] loss: 0.0155666\n",
            "[20,   300] loss: 0.0156207\n",
            "[20,   400] loss: 0.0156013\n",
            "[20,   500] loss: 0.0156168\n",
            "[20,   600] loss: 0.0155914\n",
            "        |==>  acc: 0.7034,  nmi: 0.6550  <==|\n",
            "[21,   100] loss: 0.0153420\n",
            "[21,   200] loss: 0.0153536\n",
            "[21,   300] loss: 0.0154878\n",
            "[21,   400] loss: 0.0154515\n",
            "[21,   500] loss: 0.0154208\n",
            "[21,   600] loss: 0.0153587\n",
            "        |==>  acc: 0.7026,  nmi: 0.6555  <==|\n",
            "[22,   100] loss: 0.0152054\n",
            "[22,   200] loss: 0.0153904\n",
            "[22,   300] loss: 0.0152003\n",
            "[22,   400] loss: 0.0152247\n",
            "[22,   500] loss: 0.0151310\n",
            "[22,   600] loss: 0.0152923\n",
            "        |==>  acc: 0.7274,  nmi: 0.6790  <==|\n",
            "[23,   100] loss: 0.0150953\n",
            "[23,   200] loss: 0.0150861\n",
            "[23,   300] loss: 0.0150383\n",
            "[23,   400] loss: 0.0152401\n",
            "[23,   500] loss: 0.0151895\n",
            "[23,   600] loss: 0.0149560\n",
            "        |==>  acc: 0.7835,  nmi: 0.6999  <==|\n",
            "[24,   100] loss: 0.0149144\n",
            "[24,   200] loss: 0.0149992\n",
            "[24,   300] loss: 0.0149789\n",
            "[24,   400] loss: 0.0150304\n",
            "[24,   500] loss: 0.0148897\n",
            "[24,   600] loss: 0.0148648\n",
            "        |==>  acc: 0.7125,  nmi: 0.6654  <==|\n",
            "[25,   100] loss: 0.0148089\n",
            "[25,   200] loss: 0.0148240\n",
            "[25,   300] loss: 0.0148034\n",
            "[25,   400] loss: 0.0149234\n",
            "[25,   500] loss: 0.0146764\n",
            "[25,   600] loss: 0.0147696\n",
            "        |==>  acc: 0.7154,  nmi: 0.6657  <==|\n",
            "[26,   100] loss: 0.0146516\n",
            "[26,   200] loss: 0.0146670\n",
            "[26,   300] loss: 0.0147001\n",
            "[26,   400] loss: 0.0146776\n",
            "[26,   500] loss: 0.0147893\n",
            "[26,   600] loss: 0.0145728\n",
            "        |==>  acc: 0.7768,  nmi: 0.6975  <==|\n",
            "[27,   100] loss: 0.0144649\n",
            "[27,   200] loss: 0.0145724\n",
            "[27,   300] loss: 0.0145585\n",
            "[27,   400] loss: 0.0145342\n",
            "[27,   500] loss: 0.0144742\n",
            "[27,   600] loss: 0.0145737\n",
            "        |==>  acc: 0.7949,  nmi: 0.7079  <==|\n",
            "[28,   100] loss: 0.0143436\n",
            "[28,   200] loss: 0.0144204\n",
            "[28,   300] loss: 0.0145674\n",
            "[28,   400] loss: 0.0143286\n",
            "[28,   500] loss: 0.0143531\n",
            "[28,   600] loss: 0.0145611\n",
            "        |==>  acc: 0.7811,  nmi: 0.7037  <==|\n",
            "[29,   100] loss: 0.0141566\n",
            "[29,   200] loss: 0.0144202\n",
            "[29,   300] loss: 0.0143717\n",
            "[29,   400] loss: 0.0142158\n",
            "[29,   500] loss: 0.0142883\n",
            "[29,   600] loss: 0.0143265\n",
            "        |==>  acc: 0.7868,  nmi: 0.7115  <==|\n",
            "[30,   100] loss: 0.0142215\n",
            "[30,   200] loss: 0.0142198\n",
            "[30,   300] loss: 0.0140912\n",
            "[30,   400] loss: 0.0141857\n",
            "[30,   500] loss: 0.0141577\n",
            "[30,   600] loss: 0.0142408\n",
            "        |==>  acc: 0.7798,  nmi: 0.7068  <==|\n",
            "[31,   100] loss: 0.0140452\n",
            "[31,   200] loss: 0.0140587\n",
            "[31,   300] loss: 0.0141286\n",
            "[31,   400] loss: 0.0139939\n",
            "[31,   500] loss: 0.0140324\n",
            "[31,   600] loss: 0.0141944\n",
            "        |==>  acc: 0.7895,  nmi: 0.7101  <==|\n",
            "[32,   100] loss: 0.0139841\n",
            "[32,   200] loss: 0.0140149\n",
            "[32,   300] loss: 0.0140363\n",
            "[32,   400] loss: 0.0140048\n",
            "[32,   500] loss: 0.0139902\n",
            "[32,   600] loss: 0.0138450\n",
            "        |==>  acc: 0.7895,  nmi: 0.7149  <==|\n",
            "[33,   100] loss: 0.0139122\n",
            "[33,   200] loss: 0.0138574\n",
            "[33,   300] loss: 0.0139048\n",
            "[33,   400] loss: 0.0139404\n",
            "[33,   500] loss: 0.0138826\n",
            "[33,   600] loss: 0.0138511\n",
            "        |==>  acc: 0.7966,  nmi: 0.7202  <==|\n",
            "[34,   100] loss: 0.0138184\n",
            "[34,   200] loss: 0.0137337\n",
            "[34,   300] loss: 0.0138257\n",
            "[34,   400] loss: 0.0137240\n",
            "[34,   500] loss: 0.0138828\n",
            "[34,   600] loss: 0.0137766\n",
            "        |==>  acc: 0.8037,  nmi: 0.7186  <==|\n",
            "[35,   100] loss: 0.0136659\n",
            "[35,   200] loss: 0.0136218\n",
            "[35,   300] loss: 0.0137400\n",
            "[35,   400] loss: 0.0137236\n",
            "[35,   500] loss: 0.0136395\n",
            "[35,   600] loss: 0.0138049\n",
            "        |==>  acc: 0.8072,  nmi: 0.7276  <==|\n",
            "[36,   100] loss: 0.0136990\n",
            "[36,   200] loss: 0.0136993\n",
            "[36,   300] loss: 0.0136639\n",
            "[36,   400] loss: 0.0135506\n",
            "[36,   500] loss: 0.0135763\n",
            "[36,   600] loss: 0.0135474\n",
            "        |==>  acc: 0.8056,  nmi: 0.7216  <==|\n",
            "[37,   100] loss: 0.0134686\n",
            "[37,   200] loss: 0.0134901\n",
            "[37,   300] loss: 0.0135421\n",
            "[37,   400] loss: 0.0136165\n",
            "[37,   500] loss: 0.0135845\n",
            "[37,   600] loss: 0.0134941\n",
            "        |==>  acc: 0.7998,  nmi: 0.7213  <==|\n",
            "[38,   100] loss: 0.0134669\n",
            "[38,   200] loss: 0.0135082\n",
            "[38,   300] loss: 0.0135057\n",
            "[38,   400] loss: 0.0134093\n",
            "[38,   500] loss: 0.0134109\n",
            "[38,   600] loss: 0.0134718\n",
            "        |==>  acc: 0.8004,  nmi: 0.7227  <==|\n",
            "[39,   100] loss: 0.0134675\n",
            "[39,   200] loss: 0.0133398\n",
            "[39,   300] loss: 0.0135324\n",
            "[39,   400] loss: 0.0133342\n",
            "[39,   500] loss: 0.0132754\n",
            "[39,   600] loss: 0.0133589\n",
            "        |==>  acc: 0.8174,  nmi: 0.7308  <==|\n",
            "[40,   100] loss: 0.0132864\n",
            "[40,   200] loss: 0.0132711\n",
            "[40,   300] loss: 0.0133662\n",
            "[40,   400] loss: 0.0132760\n",
            "[40,   500] loss: 0.0132280\n",
            "[40,   600] loss: 0.0133655\n",
            "        |==>  acc: 0.8031,  nmi: 0.7266  <==|\n",
            "[41,   100] loss: 0.0132472\n",
            "[41,   200] loss: 0.0132892\n",
            "[41,   300] loss: 0.0131882\n",
            "[41,   400] loss: 0.0132149\n",
            "[41,   500] loss: 0.0132411\n",
            "[41,   600] loss: 0.0132379\n",
            "        |==>  acc: 0.8160,  nmi: 0.7333  <==|\n",
            "[42,   100] loss: 0.0131646\n",
            "[42,   200] loss: 0.0131916\n",
            "[42,   300] loss: 0.0131859\n",
            "[42,   400] loss: 0.0131832\n",
            "[42,   500] loss: 0.0132084\n",
            "[42,   600] loss: 0.0130339\n",
            "        |==>  acc: 0.7983,  nmi: 0.7241  <==|\n",
            "[43,   100] loss: 0.0130409\n",
            "[43,   200] loss: 0.0131700\n",
            "[43,   300] loss: 0.0130560\n",
            "[43,   400] loss: 0.0130237\n",
            "[43,   500] loss: 0.0131451\n",
            "[43,   600] loss: 0.0131050\n",
            "        |==>  acc: 0.8075,  nmi: 0.7258  <==|\n",
            "[44,   100] loss: 0.0130370\n",
            "[44,   200] loss: 0.0130458\n",
            "[44,   300] loss: 0.0130837\n",
            "[44,   400] loss: 0.0130533\n",
            "[44,   500] loss: 0.0128382\n",
            "[44,   600] loss: 0.0130619\n",
            "        |==>  acc: 0.8101,  nmi: 0.7311  <==|\n",
            "[45,   100] loss: 0.0129124\n",
            "[45,   200] loss: 0.0129136\n",
            "[45,   300] loss: 0.0129943\n",
            "[45,   400] loss: 0.0129179\n",
            "[45,   500] loss: 0.0130794\n",
            "[45,   600] loss: 0.0129616\n",
            "        |==>  acc: 0.8034,  nmi: 0.7273  <==|\n",
            "[46,   100] loss: 0.0128284\n",
            "[46,   200] loss: 0.0129347\n",
            "[46,   300] loss: 0.0128861\n",
            "[46,   400] loss: 0.0128013\n",
            "[46,   500] loss: 0.0129445\n",
            "[46,   600] loss: 0.0129946\n",
            "        |==>  acc: 0.8150,  nmi: 0.7355  <==|\n",
            "[47,   100] loss: 0.0127597\n",
            "[47,   200] loss: 0.0128332\n",
            "[47,   300] loss: 0.0128678\n",
            "[47,   400] loss: 0.0128737\n",
            "[47,   500] loss: 0.0128875\n",
            "[47,   600] loss: 0.0128442\n",
            "        |==>  acc: 0.8150,  nmi: 0.7356  <==|\n",
            "[48,   100] loss: 0.0127095\n",
            "[48,   200] loss: 0.0127544\n",
            "[48,   300] loss: 0.0127441\n",
            "[48,   400] loss: 0.0127926\n",
            "[48,   500] loss: 0.0127451\n",
            "[48,   600] loss: 0.0129283\n",
            "        |==>  acc: 0.8179,  nmi: 0.7396  <==|\n",
            "[49,   100] loss: 0.0126871\n",
            "[49,   200] loss: 0.0126727\n",
            "[49,   300] loss: 0.0127722\n",
            "[49,   400] loss: 0.0127178\n",
            "[49,   500] loss: 0.0128155\n",
            "[49,   600] loss: 0.0127008\n",
            "        |==>  acc: 0.8180,  nmi: 0.7372  <==|\n",
            "[50,   100] loss: 0.0125340\n",
            "[50,   200] loss: 0.0126389\n",
            "[50,   300] loss: 0.0127364\n",
            "[50,   400] loss: 0.0126988\n",
            "[50,   500] loss: 0.0127124\n",
            "[50,   600] loss: 0.0126961\n",
            "        |==>  acc: 0.8167,  nmi: 0.7414  <==|\n",
            "[51,   100] loss: 0.0126064\n",
            "[51,   200] loss: 0.0126444\n",
            "[51,   300] loss: 0.0126121\n",
            "[51,   400] loss: 0.0125968\n",
            "[51,   500] loss: 0.0126569\n",
            "[51,   600] loss: 0.0125618\n",
            "        |==>  acc: 0.8169,  nmi: 0.7402  <==|\n",
            "[52,   100] loss: 0.0126443\n",
            "[52,   200] loss: 0.0125495\n",
            "[52,   300] loss: 0.0124355\n",
            "[52,   400] loss: 0.0125473\n",
            "[52,   500] loss: 0.0125942\n",
            "[52,   600] loss: 0.0126264\n",
            "        |==>  acc: 0.8220,  nmi: 0.7416  <==|\n",
            "[53,   100] loss: 0.0124118\n",
            "[53,   200] loss: 0.0125228\n",
            "[53,   300] loss: 0.0125268\n",
            "[53,   400] loss: 0.0125433\n",
            "[53,   500] loss: 0.0125870\n",
            "[53,   600] loss: 0.0124809\n",
            "        |==>  acc: 0.8252,  nmi: 0.7429  <==|\n",
            "[54,   100] loss: 0.0124308\n",
            "[54,   200] loss: 0.0124338\n",
            "[54,   300] loss: 0.0124262\n",
            "[54,   400] loss: 0.0123666\n",
            "[54,   500] loss: 0.0125092\n",
            "[54,   600] loss: 0.0125315\n",
            "        |==>  acc: 0.8241,  nmi: 0.7462  <==|\n",
            "[55,   100] loss: 0.0123382\n",
            "[55,   200] loss: 0.0124032\n",
            "[55,   300] loss: 0.0124015\n",
            "[55,   400] loss: 0.0124312\n",
            "[55,   500] loss: 0.0124616\n",
            "[55,   600] loss: 0.0124273\n",
            "        |==>  acc: 0.8264,  nmi: 0.7451  <==|\n",
            "[56,   100] loss: 0.0123010\n",
            "[56,   200] loss: 0.0123255\n",
            "[56,   300] loss: 0.0123959\n",
            "[56,   400] loss: 0.0124485\n",
            "[56,   500] loss: 0.0123584\n",
            "[56,   600] loss: 0.0123423\n",
            "        |==>  acc: 0.8296,  nmi: 0.7507  <==|\n",
            "[57,   100] loss: 0.0123336\n",
            "[57,   200] loss: 0.0121559\n",
            "[57,   300] loss: 0.0123890\n",
            "[57,   400] loss: 0.0123471\n",
            "[57,   500] loss: 0.0124173\n",
            "[57,   600] loss: 0.0122566\n",
            "        |==>  acc: 0.8218,  nmi: 0.7442  <==|\n",
            "[58,   100] loss: 0.0122060\n",
            "[58,   200] loss: 0.0122673\n",
            "[58,   300] loss: 0.0123149\n",
            "[58,   400] loss: 0.0122036\n",
            "[58,   500] loss: 0.0123653\n",
            "[58,   600] loss: 0.0122427\n",
            "        |==>  acc: 0.8243,  nmi: 0.7456  <==|\n",
            "[59,   100] loss: 0.0122045\n",
            "[59,   200] loss: 0.0122033\n",
            "[59,   300] loss: 0.0123166\n",
            "[59,   400] loss: 0.0121466\n",
            "[59,   500] loss: 0.0122018\n",
            "[59,   600] loss: 0.0122486\n",
            "        |==>  acc: 0.8268,  nmi: 0.7467  <==|\n",
            "[60,   100] loss: 0.0122244\n",
            "[60,   200] loss: 0.0122135\n",
            "[60,   300] loss: 0.0120840\n",
            "[60,   400] loss: 0.0121548\n",
            "[60,   500] loss: 0.0122579\n",
            "[60,   600] loss: 0.0121693\n",
            "        |==>  acc: 0.8221,  nmi: 0.7468  <==|\n",
            "[61,   100] loss: 0.0120644\n",
            "[61,   200] loss: 0.0122019\n",
            "[61,   300] loss: 0.0121120\n",
            "[61,   400] loss: 0.0121130\n",
            "[61,   500] loss: 0.0122053\n",
            "[61,   600] loss: 0.0121348\n",
            "        |==>  acc: 0.8248,  nmi: 0.7493  <==|\n",
            "[62,   100] loss: 0.0120275\n",
            "[62,   200] loss: 0.0121499\n",
            "[62,   300] loss: 0.0120565\n",
            "[62,   400] loss: 0.0120527\n",
            "[62,   500] loss: 0.0122000\n",
            "[62,   600] loss: 0.0121273\n",
            "        |==>  acc: 0.8330,  nmi: 0.7502  <==|\n",
            "[63,   100] loss: 0.0120974\n",
            "[63,   200] loss: 0.0119692\n",
            "[63,   300] loss: 0.0120841\n",
            "[63,   400] loss: 0.0120703\n",
            "[63,   500] loss: 0.0120705\n",
            "[63,   600] loss: 0.0120485\n",
            "        |==>  acc: 0.8264,  nmi: 0.7479  <==|\n",
            "[64,   100] loss: 0.0119348\n",
            "[64,   200] loss: 0.0118780\n",
            "[64,   300] loss: 0.0119795\n",
            "[64,   400] loss: 0.0121414\n",
            "[64,   500] loss: 0.0121636\n",
            "[64,   600] loss: 0.0119787\n",
            "        |==>  acc: 0.8340,  nmi: 0.7498  <==|\n",
            "[65,   100] loss: 0.0119356\n",
            "[65,   200] loss: 0.0119462\n",
            "[65,   300] loss: 0.0119419\n",
            "[65,   400] loss: 0.0119329\n",
            "[65,   500] loss: 0.0121512\n",
            "[65,   600] loss: 0.0120122\n",
            "        |==>  acc: 0.8291,  nmi: 0.7487  <==|\n",
            "[66,   100] loss: 0.0119053\n",
            "[66,   200] loss: 0.0118673\n",
            "[66,   300] loss: 0.0120047\n",
            "[66,   400] loss: 0.0119135\n",
            "[66,   500] loss: 0.0119960\n",
            "[66,   600] loss: 0.0119250\n",
            "        |==>  acc: 0.8281,  nmi: 0.7510  <==|\n",
            "[67,   100] loss: 0.0118787\n",
            "[67,   200] loss: 0.0118551\n",
            "[67,   300] loss: 0.0118418\n",
            "[67,   400] loss: 0.0119032\n",
            "[67,   500] loss: 0.0119740\n",
            "[67,   600] loss: 0.0119913\n",
            "        |==>  acc: 0.8313,  nmi: 0.7493  <==|\n",
            "[68,   100] loss: 0.0118973\n",
            "[68,   200] loss: 0.0117472\n",
            "[68,   300] loss: 0.0119151\n",
            "[68,   400] loss: 0.0119179\n",
            "[68,   500] loss: 0.0118577\n",
            "[68,   600] loss: 0.0118966\n",
            "        |==>  acc: 0.8284,  nmi: 0.7520  <==|\n",
            "[69,   100] loss: 0.0117783\n",
            "[69,   200] loss: 0.0118640\n",
            "[69,   300] loss: 0.0118450\n",
            "[69,   400] loss: 0.0118082\n",
            "[69,   500] loss: 0.0118298\n",
            "[69,   600] loss: 0.0118466\n",
            "        |==>  acc: 0.8250,  nmi: 0.7484  <==|\n",
            "[70,   100] loss: 0.0117826\n",
            "[70,   200] loss: 0.0117205\n",
            "[70,   300] loss: 0.0118079\n",
            "[70,   400] loss: 0.0119106\n",
            "[70,   500] loss: 0.0117871\n",
            "[70,   600] loss: 0.0117644\n",
            "        |==>  acc: 0.8243,  nmi: 0.7494  <==|\n",
            "[71,   100] loss: 0.0117510\n",
            "[71,   200] loss: 0.0117637\n",
            "[71,   300] loss: 0.0117473\n",
            "[71,   400] loss: 0.0118164\n",
            "[71,   500] loss: 0.0117601\n",
            "[71,   600] loss: 0.0117694\n",
            "        |==>  acc: 0.8312,  nmi: 0.7520  <==|\n",
            "[72,   100] loss: 0.0116200\n",
            "[72,   200] loss: 0.0116872\n",
            "[72,   300] loss: 0.0117403\n",
            "[72,   400] loss: 0.0117942\n",
            "[72,   500] loss: 0.0118702\n",
            "[72,   600] loss: 0.0116940\n",
            "        |==>  acc: 0.8353,  nmi: 0.7574  <==|\n",
            "[73,   100] loss: 0.0115906\n",
            "[73,   200] loss: 0.0116248\n",
            "[73,   300] loss: 0.0116169\n",
            "[73,   400] loss: 0.0117766\n",
            "[73,   500] loss: 0.0117400\n",
            "[73,   600] loss: 0.0118455\n",
            "        |==>  acc: 0.8315,  nmi: 0.7544  <==|\n",
            "[74,   100] loss: 0.0116453\n",
            "[74,   200] loss: 0.0117191\n",
            "[74,   300] loss: 0.0117060\n",
            "[74,   400] loss: 0.0117456\n",
            "[74,   500] loss: 0.0115742\n",
            "[74,   600] loss: 0.0116205\n",
            "        |==>  acc: 0.8410,  nmi: 0.7584  <==|\n",
            "[75,   100] loss: 0.0115678\n",
            "[75,   200] loss: 0.0117277\n",
            "[75,   300] loss: 0.0115848\n",
            "[75,   400] loss: 0.0116506\n",
            "[75,   500] loss: 0.0116548\n",
            "[75,   600] loss: 0.0116294\n",
            "        |==>  acc: 0.8320,  nmi: 0.7572  <==|\n",
            "[76,   100] loss: 0.0115799\n",
            "[76,   200] loss: 0.0116093\n",
            "[76,   300] loss: 0.0116432\n",
            "[76,   400] loss: 0.0115850\n",
            "[76,   500] loss: 0.0114947\n",
            "[76,   600] loss: 0.0116610\n",
            "        |==>  acc: 0.8341,  nmi: 0.7560  <==|\n",
            "[77,   100] loss: 0.0115479\n",
            "[77,   200] loss: 0.0115883\n",
            "[77,   300] loss: 0.0115297\n",
            "[77,   400] loss: 0.0115552\n",
            "[77,   500] loss: 0.0116078\n",
            "[77,   600] loss: 0.0116356\n",
            "        |==>  acc: 0.8345,  nmi: 0.7563  <==|\n",
            "[78,   100] loss: 0.0115242\n",
            "[78,   200] loss: 0.0114770\n",
            "[78,   300] loss: 0.0115897\n",
            "[78,   400] loss: 0.0114497\n",
            "[78,   500] loss: 0.0115582\n",
            "[78,   600] loss: 0.0116340\n",
            "        |==>  acc: 0.8361,  nmi: 0.7589  <==|\n",
            "[79,   100] loss: 0.0115080\n",
            "[79,   200] loss: 0.0114167\n",
            "[79,   300] loss: 0.0115074\n",
            "[79,   400] loss: 0.0115419\n",
            "[79,   500] loss: 0.0116487\n",
            "[79,   600] loss: 0.0114118\n",
            "        |==>  acc: 0.8360,  nmi: 0.7590  <==|\n",
            "[80,   100] loss: 0.0113724\n",
            "[80,   200] loss: 0.0115078\n",
            "[80,   300] loss: 0.0114970\n",
            "[80,   400] loss: 0.0114999\n",
            "[80,   500] loss: 0.0115779\n",
            "[80,   600] loss: 0.0114734\n",
            "        |==>  acc: 0.8389,  nmi: 0.7602  <==|\n",
            "[81,   100] loss: 0.0113410\n",
            "[81,   200] loss: 0.0114063\n",
            "[81,   300] loss: 0.0114619\n",
            "[81,   400] loss: 0.0114501\n",
            "[81,   500] loss: 0.0115211\n",
            "[81,   600] loss: 0.0115376\n",
            "        |==>  acc: 0.8325,  nmi: 0.7556  <==|\n",
            "[82,   100] loss: 0.0113723\n",
            "[82,   200] loss: 0.0114994\n",
            "[82,   300] loss: 0.0114592\n",
            "[82,   400] loss: 0.0113635\n",
            "[82,   500] loss: 0.0115117\n",
            "[82,   600] loss: 0.0113758\n",
            "        |==>  acc: 0.8273,  nmi: 0.7547  <==|\n",
            "[83,   100] loss: 0.0112602\n",
            "[83,   200] loss: 0.0114161\n",
            "[83,   300] loss: 0.0113140\n",
            "[83,   400] loss: 0.0115096\n",
            "[83,   500] loss: 0.0114487\n",
            "[83,   600] loss: 0.0114635\n",
            "        |==>  acc: 0.8328,  nmi: 0.7562  <==|\n",
            "[84,   100] loss: 0.0111563\n",
            "[84,   200] loss: 0.0113632\n",
            "[84,   300] loss: 0.0114062\n",
            "[84,   400] loss: 0.0113529\n",
            "[84,   500] loss: 0.0114200\n",
            "[84,   600] loss: 0.0114812\n",
            "        |==>  acc: 0.8372,  nmi: 0.7575  <==|\n",
            "[85,   100] loss: 0.0111759\n",
            "[85,   200] loss: 0.0113843\n",
            "[85,   300] loss: 0.0112852\n",
            "[85,   400] loss: 0.0113971\n",
            "[85,   500] loss: 0.0114220\n",
            "[85,   600] loss: 0.0113362\n",
            "        |==>  acc: 0.8421,  nmi: 0.7615  <==|\n",
            "[86,   100] loss: 0.0112121\n",
            "[86,   200] loss: 0.0113040\n",
            "[86,   300] loss: 0.0113644\n",
            "[86,   400] loss: 0.0113345\n",
            "[86,   500] loss: 0.0113819\n",
            "[86,   600] loss: 0.0113326\n",
            "        |==>  acc: 0.8390,  nmi: 0.7656  <==|\n",
            "[87,   100] loss: 0.0112723\n",
            "[87,   200] loss: 0.0111805\n",
            "[87,   300] loss: 0.0112888\n",
            "[87,   400] loss: 0.0113607\n",
            "[87,   500] loss: 0.0113268\n",
            "[87,   600] loss: 0.0113122\n",
            "        |==>  acc: 0.8316,  nmi: 0.7575  <==|\n",
            "[88,   100] loss: 0.0111683\n",
            "[88,   200] loss: 0.0112105\n",
            "[88,   300] loss: 0.0112171\n",
            "[88,   400] loss: 0.0113402\n",
            "[88,   500] loss: 0.0113176\n",
            "[88,   600] loss: 0.0113893\n",
            "        |==>  acc: 0.8371,  nmi: 0.7593  <==|\n",
            "[89,   100] loss: 0.0111619\n",
            "[89,   200] loss: 0.0111713\n",
            "[89,   300] loss: 0.0112993\n",
            "[89,   400] loss: 0.0112120\n",
            "[89,   500] loss: 0.0113581\n",
            "[89,   600] loss: 0.0112393\n",
            "        |==>  acc: 0.8416,  nmi: 0.7627  <==|\n",
            "[90,   100] loss: 0.0111819\n",
            "[90,   200] loss: 0.0112941\n",
            "[90,   300] loss: 0.0112035\n",
            "[90,   400] loss: 0.0112119\n",
            "[90,   500] loss: 0.0111726\n",
            "[90,   600] loss: 0.0112203\n",
            "        |==>  acc: 0.8393,  nmi: 0.7588  <==|\n",
            "[91,   100] loss: 0.0111624\n",
            "[91,   200] loss: 0.0111756\n",
            "[91,   300] loss: 0.0111337\n",
            "[91,   400] loss: 0.0112352\n",
            "[91,   500] loss: 0.0112716\n",
            "[91,   600] loss: 0.0112084\n",
            "        |==>  acc: 0.8425,  nmi: 0.7642  <==|\n",
            "[92,   100] loss: 0.0111347\n",
            "[92,   200] loss: 0.0111211\n",
            "[92,   300] loss: 0.0111784\n",
            "[92,   400] loss: 0.0112586\n",
            "[92,   500] loss: 0.0111048\n",
            "[92,   600] loss: 0.0111532\n",
            "        |==>  acc: 0.8345,  nmi: 0.7586  <==|\n",
            "[93,   100] loss: 0.0110137\n",
            "[93,   200] loss: 0.0110787\n",
            "[93,   300] loss: 0.0112169\n",
            "[93,   400] loss: 0.0110596\n",
            "[93,   500] loss: 0.0112050\n",
            "[93,   600] loss: 0.0113106\n",
            "        |==>  acc: 0.8409,  nmi: 0.7640  <==|\n",
            "[94,   100] loss: 0.0110718\n",
            "[94,   200] loss: 0.0110651\n",
            "[94,   300] loss: 0.0111111\n",
            "[94,   400] loss: 0.0111302\n",
            "[94,   500] loss: 0.0112084\n",
            "[94,   600] loss: 0.0111499\n",
            "        |==>  acc: 0.8415,  nmi: 0.7617  <==|\n",
            "[95,   100] loss: 0.0111200\n",
            "[95,   200] loss: 0.0110092\n",
            "[95,   300] loss: 0.0110887\n",
            "[95,   400] loss: 0.0111999\n",
            "[95,   500] loss: 0.0110515\n",
            "[95,   600] loss: 0.0110843\n",
            "        |==>  acc: 0.8420,  nmi: 0.7662  <==|\n",
            "[96,   100] loss: 0.0110659\n",
            "[96,   200] loss: 0.0110493\n",
            "[96,   300] loss: 0.0110965\n",
            "[96,   400] loss: 0.0111028\n",
            "[96,   500] loss: 0.0110148\n",
            "[96,   600] loss: 0.0111060\n",
            "        |==>  acc: 0.8455,  nmi: 0.7658  <==|\n",
            "[97,   100] loss: 0.0110029\n",
            "[97,   200] loss: 0.0110342\n",
            "[97,   300] loss: 0.0110856\n",
            "[97,   400] loss: 0.0109974\n",
            "[97,   500] loss: 0.0110334\n",
            "[97,   600] loss: 0.0111356\n",
            "        |==>  acc: 0.8435,  nmi: 0.7664  <==|\n",
            "[98,   100] loss: 0.0109134\n",
            "[98,   200] loss: 0.0111193\n",
            "[98,   300] loss: 0.0110383\n",
            "[98,   400] loss: 0.0109870\n",
            "[98,   500] loss: 0.0110756\n",
            "[98,   600] loss: 0.0110216\n",
            "        |==>  acc: 0.8467,  nmi: 0.7687  <==|\n",
            "[99,   100] loss: 0.0108410\n",
            "[99,   200] loss: 0.0109207\n",
            "[99,   300] loss: 0.0110101\n",
            "[99,   400] loss: 0.0110645\n",
            "[99,   500] loss: 0.0110395\n",
            "[99,   600] loss: 0.0110871\n",
            "        |==>  acc: 0.8401,  nmi: 0.7662  <==|\n",
            "[100,   100] loss: 0.0109407\n",
            "[100,   200] loss: 0.0109370\n",
            "[100,   300] loss: 0.0109245\n",
            "[100,   400] loss: 0.0110158\n",
            "[100,   500] loss: 0.0110354\n",
            "[100,   600] loss: 0.0109936\n",
            "        |==>  acc: 0.8465,  nmi: 0.7682  <==|\n",
            "[101,   100] loss: 0.0108251\n",
            "[101,   200] loss: 0.0109662\n",
            "[101,   300] loss: 0.0109663\n",
            "[101,   400] loss: 0.0110251\n",
            "[101,   500] loss: 0.0108836\n",
            "[101,   600] loss: 0.0111143\n",
            "        |==>  acc: 0.8399,  nmi: 0.7652  <==|\n",
            "[102,   100] loss: 0.0108894\n",
            "[102,   200] loss: 0.0108133\n",
            "[102,   300] loss: 0.0109558\n",
            "[102,   400] loss: 0.0109933\n",
            "[102,   500] loss: 0.0110807\n",
            "[102,   600] loss: 0.0109529\n",
            "        |==>  acc: 0.8449,  nmi: 0.7686  <==|\n",
            "[103,   100] loss: 0.0109047\n",
            "[103,   200] loss: 0.0109856\n",
            "[103,   300] loss: 0.0109298\n",
            "[103,   400] loss: 0.0109259\n",
            "[103,   500] loss: 0.0108641\n",
            "[103,   600] loss: 0.0109645\n",
            "        |==>  acc: 0.8449,  nmi: 0.7675  <==|\n",
            "[104,   100] loss: 0.0108878\n",
            "[104,   200] loss: 0.0109229\n",
            "[104,   300] loss: 0.0108735\n",
            "[104,   400] loss: 0.0109018\n",
            "[104,   500] loss: 0.0109292\n",
            "[104,   600] loss: 0.0108791\n",
            "        |==>  acc: 0.8491,  nmi: 0.7724  <==|\n",
            "[105,   100] loss: 0.0108813\n",
            "[105,   200] loss: 0.0107906\n",
            "[105,   300] loss: 0.0109555\n",
            "[105,   400] loss: 0.0108246\n",
            "[105,   500] loss: 0.0108382\n",
            "[105,   600] loss: 0.0109236\n",
            "        |==>  acc: 0.8454,  nmi: 0.7668  <==|\n",
            "[106,   100] loss: 0.0108479\n",
            "[106,   200] loss: 0.0109026\n",
            "[106,   300] loss: 0.0108189\n",
            "[106,   400] loss: 0.0108812\n",
            "[106,   500] loss: 0.0108793\n",
            "[106,   600] loss: 0.0108626\n",
            "        |==>  acc: 0.8443,  nmi: 0.7668  <==|\n",
            "[107,   100] loss: 0.0107079\n",
            "[107,   200] loss: 0.0108637\n",
            "[107,   300] loss: 0.0108150\n",
            "[107,   400] loss: 0.0108897\n",
            "[107,   500] loss: 0.0108485\n",
            "[107,   600] loss: 0.0108924\n",
            "        |==>  acc: 0.8471,  nmi: 0.7682  <==|\n",
            "[108,   100] loss: 0.0107963\n",
            "[108,   200] loss: 0.0107784\n",
            "[108,   300] loss: 0.0108599\n",
            "[108,   400] loss: 0.0108895\n",
            "[108,   500] loss: 0.0108184\n",
            "[108,   600] loss: 0.0108813\n",
            "        |==>  acc: 0.8442,  nmi: 0.7677  <==|\n",
            "[109,   100] loss: 0.0107515\n",
            "[109,   200] loss: 0.0106976\n",
            "[109,   300] loss: 0.0108096\n",
            "[109,   400] loss: 0.0109409\n",
            "[109,   500] loss: 0.0108096\n",
            "[109,   600] loss: 0.0108117\n",
            "        |==>  acc: 0.8458,  nmi: 0.7702  <==|\n",
            "[110,   100] loss: 0.0107253\n",
            "[110,   200] loss: 0.0107771\n",
            "[110,   300] loss: 0.0107955\n",
            "[110,   400] loss: 0.0108403\n",
            "[110,   500] loss: 0.0108008\n",
            "[110,   600] loss: 0.0107095\n",
            "        |==>  acc: 0.8449,  nmi: 0.7699  <==|\n",
            "[111,   100] loss: 0.0106611\n",
            "[111,   200] loss: 0.0107802\n",
            "[111,   300] loss: 0.0108077\n",
            "[111,   400] loss: 0.0107399\n",
            "[111,   500] loss: 0.0107321\n",
            "[111,   600] loss: 0.0108126\n",
            "        |==>  acc: 0.8431,  nmi: 0.7691  <==|\n",
            "[112,   100] loss: 0.0106790\n",
            "[112,   200] loss: 0.0107036\n",
            "[112,   300] loss: 0.0107691\n",
            "[112,   400] loss: 0.0108098\n",
            "[112,   500] loss: 0.0107526\n",
            "[112,   600] loss: 0.0107244\n",
            "        |==>  acc: 0.8395,  nmi: 0.7635  <==|\n",
            "[113,   100] loss: 0.0106228\n",
            "[113,   200] loss: 0.0106697\n",
            "[113,   300] loss: 0.0107655\n",
            "[113,   400] loss: 0.0106931\n",
            "[113,   500] loss: 0.0107866\n",
            "[113,   600] loss: 0.0108134\n",
            "        |==>  acc: 0.8480,  nmi: 0.7703  <==|\n",
            "[114,   100] loss: 0.0105887\n",
            "[114,   200] loss: 0.0106785\n",
            "[114,   300] loss: 0.0107481\n",
            "[114,   400] loss: 0.0107635\n",
            "[114,   500] loss: 0.0106819\n",
            "[114,   600] loss: 0.0107667\n",
            "        |==>  acc: 0.8472,  nmi: 0.7702  <==|\n",
            "[115,   100] loss: 0.0105898\n",
            "[115,   200] loss: 0.0106090\n",
            "[115,   300] loss: 0.0106259\n",
            "[115,   400] loss: 0.0106732\n",
            "[115,   500] loss: 0.0108754\n",
            "[115,   600] loss: 0.0107341\n",
            "        |==>  acc: 0.8451,  nmi: 0.7665  <==|\n",
            "[116,   100] loss: 0.0105303\n",
            "[116,   200] loss: 0.0106790\n",
            "[116,   300] loss: 0.0106468\n",
            "[116,   400] loss: 0.0107502\n",
            "[116,   500] loss: 0.0106803\n",
            "[116,   600] loss: 0.0107286\n",
            "        |==>  acc: 0.8455,  nmi: 0.7687  <==|\n",
            "[117,   100] loss: 0.0106298\n",
            "[117,   200] loss: 0.0107175\n",
            "[117,   300] loss: 0.0105401\n",
            "[117,   400] loss: 0.0106063\n",
            "[117,   500] loss: 0.0107434\n",
            "[117,   600] loss: 0.0106618\n",
            "        |==>  acc: 0.8477,  nmi: 0.7726  <==|\n",
            "[118,   100] loss: 0.0106379\n",
            "[118,   200] loss: 0.0105947\n",
            "[118,   300] loss: 0.0105926\n",
            "[118,   400] loss: 0.0105876\n",
            "[118,   500] loss: 0.0107298\n",
            "[118,   600] loss: 0.0106928\n",
            "        |==>  acc: 0.8451,  nmi: 0.7671  <==|\n",
            "[119,   100] loss: 0.0106201\n",
            "[119,   200] loss: 0.0106523\n",
            "[119,   300] loss: 0.0106348\n",
            "[119,   400] loss: 0.0105982\n",
            "[119,   500] loss: 0.0106394\n",
            "[119,   600] loss: 0.0105975\n",
            "        |==>  acc: 0.8429,  nmi: 0.7679  <==|\n",
            "[120,   100] loss: 0.0104903\n",
            "[120,   200] loss: 0.0105885\n",
            "[120,   300] loss: 0.0105690\n",
            "[120,   400] loss: 0.0105770\n",
            "[120,   500] loss: 0.0106138\n",
            "[120,   600] loss: 0.0107345\n",
            "        |==>  acc: 0.8506,  nmi: 0.7716  <==|\n",
            "[121,   100] loss: 0.0105071\n",
            "[121,   200] loss: 0.0104949\n",
            "[121,   300] loss: 0.0105227\n",
            "[121,   400] loss: 0.0106572\n",
            "[121,   500] loss: 0.0106104\n",
            "[121,   600] loss: 0.0106544\n",
            "        |==>  acc: 0.8473,  nmi: 0.7714  <==|\n",
            "[122,   100] loss: 0.0104810\n",
            "[122,   200] loss: 0.0105729\n",
            "[122,   300] loss: 0.0105416\n",
            "[122,   400] loss: 0.0105444\n",
            "[122,   500] loss: 0.0106344\n",
            "[122,   600] loss: 0.0106210\n",
            "        |==>  acc: 0.8441,  nmi: 0.7703  <==|\n",
            "[123,   100] loss: 0.0104879\n",
            "[123,   200] loss: 0.0105070\n",
            "[123,   300] loss: 0.0105490\n",
            "[123,   400] loss: 0.0105788\n",
            "[123,   500] loss: 0.0106435\n",
            "[123,   600] loss: 0.0105042\n",
            "        |==>  acc: 0.8479,  nmi: 0.7722  <==|\n",
            "[124,   100] loss: 0.0105643\n",
            "[124,   200] loss: 0.0105168\n",
            "[124,   300] loss: 0.0105304\n",
            "[124,   400] loss: 0.0105347\n",
            "[124,   500] loss: 0.0105889\n",
            "[124,   600] loss: 0.0104782\n",
            "        |==>  acc: 0.8476,  nmi: 0.7703  <==|\n",
            "[125,   100] loss: 0.0104347\n",
            "[125,   200] loss: 0.0105009\n",
            "[125,   300] loss: 0.0104915\n",
            "[125,   400] loss: 0.0105667\n",
            "[125,   500] loss: 0.0105067\n",
            "[125,   600] loss: 0.0105787\n",
            "        |==>  acc: 0.8487,  nmi: 0.7696  <==|\n",
            "[126,   100] loss: 0.0104827\n",
            "[126,   200] loss: 0.0105458\n",
            "[126,   300] loss: 0.0105526\n",
            "[126,   400] loss: 0.0104476\n",
            "[126,   500] loss: 0.0105039\n",
            "[126,   600] loss: 0.0104957\n",
            "        |==>  acc: 0.8483,  nmi: 0.7714  <==|\n",
            "[127,   100] loss: 0.0104385\n",
            "[127,   200] loss: 0.0104858\n",
            "[127,   300] loss: 0.0105452\n",
            "[127,   400] loss: 0.0104589\n",
            "[127,   500] loss: 0.0105200\n",
            "[127,   600] loss: 0.0104676\n",
            "        |==>  acc: 0.8497,  nmi: 0.7724  <==|\n",
            "[128,   100] loss: 0.0104082\n",
            "[128,   200] loss: 0.0104315\n",
            "[128,   300] loss: 0.0105084\n",
            "[128,   400] loss: 0.0104991\n",
            "[128,   500] loss: 0.0105058\n",
            "[128,   600] loss: 0.0104267\n",
            "        |==>  acc: 0.8427,  nmi: 0.7671  <==|\n",
            "[129,   100] loss: 0.0104187\n",
            "[129,   200] loss: 0.0105012\n",
            "[129,   300] loss: 0.0104281\n",
            "[129,   400] loss: 0.0104879\n",
            "[129,   500] loss: 0.0103864\n",
            "[129,   600] loss: 0.0105142\n",
            "        |==>  acc: 0.8488,  nmi: 0.7760  <==|\n",
            "[130,   100] loss: 0.0103162\n",
            "[130,   200] loss: 0.0104719\n",
            "[130,   300] loss: 0.0104189\n",
            "[130,   400] loss: 0.0104479\n",
            "[130,   500] loss: 0.0104963\n",
            "[130,   600] loss: 0.0105041\n",
            "        |==>  acc: 0.8456,  nmi: 0.7713  <==|\n",
            "[131,   100] loss: 0.0103592\n",
            "[131,   200] loss: 0.0103794\n",
            "[131,   300] loss: 0.0104201\n",
            "[131,   400] loss: 0.0104113\n",
            "[131,   500] loss: 0.0105245\n",
            "[131,   600] loss: 0.0104481\n",
            "        |==>  acc: 0.8477,  nmi: 0.7732  <==|\n",
            "[132,   100] loss: 0.0101845\n",
            "[132,   200] loss: 0.0104594\n",
            "[132,   300] loss: 0.0105118\n",
            "[132,   400] loss: 0.0104859\n",
            "[132,   500] loss: 0.0103844\n",
            "[132,   600] loss: 0.0104365\n",
            "        |==>  acc: 0.8439,  nmi: 0.7688  <==|\n",
            "[133,   100] loss: 0.0103767\n",
            "[133,   200] loss: 0.0103654\n",
            "[133,   300] loss: 0.0104094\n",
            "[133,   400] loss: 0.0104258\n",
            "[133,   500] loss: 0.0104318\n",
            "[133,   600] loss: 0.0103891\n",
            "        |==>  acc: 0.8457,  nmi: 0.7708  <==|\n",
            "[134,   100] loss: 0.0103895\n",
            "[134,   200] loss: 0.0103752\n",
            "[134,   300] loss: 0.0103353\n",
            "[134,   400] loss: 0.0103779\n",
            "[134,   500] loss: 0.0103846\n",
            "[134,   600] loss: 0.0104513\n",
            "        |==>  acc: 0.8480,  nmi: 0.7707  <==|\n",
            "[135,   100] loss: 0.0102329\n",
            "[135,   200] loss: 0.0103512\n",
            "[135,   300] loss: 0.0104107\n",
            "[135,   400] loss: 0.0103385\n",
            "[135,   500] loss: 0.0103900\n",
            "[135,   600] loss: 0.0104715\n",
            "        |==>  acc: 0.8468,  nmi: 0.7725  <==|\n",
            "[136,   100] loss: 0.0103382\n",
            "[136,   200] loss: 0.0103022\n",
            "[136,   300] loss: 0.0102267\n",
            "[136,   400] loss: 0.0102804\n",
            "[136,   500] loss: 0.0105049\n",
            "[136,   600] loss: 0.0104705\n",
            "        |==>  acc: 0.8411,  nmi: 0.7714  <==|\n",
            "[137,   100] loss: 0.0103428\n",
            "[137,   200] loss: 0.0101619\n",
            "[137,   300] loss: 0.0103646\n",
            "[137,   400] loss: 0.0103584\n",
            "[137,   500] loss: 0.0103860\n",
            "[137,   600] loss: 0.0104120\n",
            "        |==>  acc: 0.8418,  nmi: 0.7711  <==|\n",
            "[138,   100] loss: 0.0102947\n",
            "[138,   200] loss: 0.0102761\n",
            "[138,   300] loss: 0.0103238\n",
            "[138,   400] loss: 0.0102414\n",
            "[138,   500] loss: 0.0103491\n",
            "[138,   600] loss: 0.0104206\n",
            "        |==>  acc: 0.8451,  nmi: 0.7693  <==|\n",
            "[139,   100] loss: 0.0101326\n",
            "[139,   200] loss: 0.0103077\n",
            "[139,   300] loss: 0.0103054\n",
            "[139,   400] loss: 0.0103933\n",
            "[139,   500] loss: 0.0103260\n",
            "[139,   600] loss: 0.0103755\n",
            "        |==>  acc: 0.8468,  nmi: 0.7718  <==|\n",
            "[140,   100] loss: 0.0102298\n",
            "[140,   200] loss: 0.0102738\n",
            "[140,   300] loss: 0.0101809\n",
            "[140,   400] loss: 0.0103441\n",
            "[140,   500] loss: 0.0103846\n",
            "[140,   600] loss: 0.0103664\n",
            "        |==>  acc: 0.8455,  nmi: 0.7706  <==|\n",
            "[141,   100] loss: 0.0102681\n",
            "[141,   200] loss: 0.0102367\n",
            "[141,   300] loss: 0.0102878\n",
            "[141,   400] loss: 0.0102721\n",
            "[141,   500] loss: 0.0103593\n",
            "[141,   600] loss: 0.0102769\n",
            "        |==>  acc: 0.8499,  nmi: 0.7775  <==|\n",
            "[142,   100] loss: 0.0101945\n",
            "[142,   200] loss: 0.0102285\n",
            "[142,   300] loss: 0.0103475\n",
            "[142,   400] loss: 0.0102743\n",
            "[142,   500] loss: 0.0102324\n",
            "[142,   600] loss: 0.0102294\n",
            "        |==>  acc: 0.8504,  nmi: 0.7745  <==|\n",
            "[143,   100] loss: 0.0102051\n",
            "[143,   200] loss: 0.0102015\n",
            "[143,   300] loss: 0.0103104\n",
            "[143,   400] loss: 0.0102071\n",
            "[143,   500] loss: 0.0102762\n",
            "[143,   600] loss: 0.0103596\n",
            "        |==>  acc: 0.8485,  nmi: 0.7738  <==|\n",
            "[144,   100] loss: 0.0102002\n",
            "[144,   200] loss: 0.0101719\n",
            "[144,   300] loss: 0.0102818\n",
            "[144,   400] loss: 0.0102420\n",
            "[144,   500] loss: 0.0102787\n",
            "[144,   600] loss: 0.0102226\n",
            "        |==>  acc: 0.8455,  nmi: 0.7719  <==|\n",
            "[145,   100] loss: 0.0101669\n",
            "[145,   200] loss: 0.0102085\n",
            "[145,   300] loss: 0.0102088\n",
            "[145,   400] loss: 0.0101613\n",
            "[145,   500] loss: 0.0102761\n",
            "[145,   600] loss: 0.0102868\n",
            "        |==>  acc: 0.8492,  nmi: 0.7735  <==|\n",
            "[146,   100] loss: 0.0101584\n",
            "[146,   200] loss: 0.0101693\n",
            "[146,   300] loss: 0.0102811\n",
            "[146,   400] loss: 0.0101900\n",
            "[146,   500] loss: 0.0102780\n",
            "[146,   600] loss: 0.0102179\n",
            "        |==>  acc: 0.8490,  nmi: 0.7751  <==|\n",
            "[147,   100] loss: 0.0102534\n",
            "[147,   200] loss: 0.0101602\n",
            "[147,   300] loss: 0.0100975\n",
            "[147,   400] loss: 0.0102383\n",
            "[147,   500] loss: 0.0101804\n",
            "[147,   600] loss: 0.0102643\n",
            "        |==>  acc: 0.8473,  nmi: 0.7715  <==|\n",
            "[148,   100] loss: 0.0101292\n",
            "[148,   200] loss: 0.0101541\n",
            "[148,   300] loss: 0.0102243\n",
            "[148,   400] loss: 0.0101715\n",
            "[148,   500] loss: 0.0101925\n",
            "[148,   600] loss: 0.0102693\n",
            "        |==>  acc: 0.8470,  nmi: 0.7728  <==|\n",
            "[149,   100] loss: 0.0100899\n",
            "[149,   200] loss: 0.0101774\n",
            "[149,   300] loss: 0.0101587\n",
            "[149,   400] loss: 0.0102512\n",
            "[149,   500] loss: 0.0101710\n",
            "[149,   600] loss: 0.0101627\n",
            "        |==>  acc: 0.8463,  nmi: 0.7721  <==|\n",
            "[150,   100] loss: 0.0100821\n",
            "[150,   200] loss: 0.0100968\n",
            "[150,   300] loss: 0.0101765\n",
            "[150,   400] loss: 0.0101537\n",
            "[150,   500] loss: 0.0102156\n",
            "[150,   600] loss: 0.0102178\n",
            "        |==>  acc: 0.8449,  nmi: 0.7727  <==|\n",
            "[151,   100] loss: 0.0101055\n",
            "[151,   200] loss: 0.0100311\n",
            "[151,   300] loss: 0.0101341\n",
            "[151,   400] loss: 0.0102129\n",
            "[151,   500] loss: 0.0101190\n",
            "[151,   600] loss: 0.0102340\n",
            "        |==>  acc: 0.8378,  nmi: 0.7668  <==|\n",
            "[152,   100] loss: 0.0101011\n",
            "[152,   200] loss: 0.0101169\n",
            "[152,   300] loss: 0.0100667\n",
            "[152,   400] loss: 0.0101573\n",
            "[152,   500] loss: 0.0102559\n",
            "[152,   600] loss: 0.0101568\n",
            "        |==>  acc: 0.8481,  nmi: 0.7756  <==|\n",
            "[153,   100] loss: 0.0100231\n",
            "[153,   200] loss: 0.0100501\n",
            "[153,   300] loss: 0.0101416\n",
            "[153,   400] loss: 0.0100578\n",
            "[153,   500] loss: 0.0102780\n",
            "[153,   600] loss: 0.0101757\n",
            "        |==>  acc: 0.8467,  nmi: 0.7736  <==|\n",
            "[154,   100] loss: 0.0099344\n",
            "[154,   200] loss: 0.0101391\n",
            "[154,   300] loss: 0.0101211\n",
            "[154,   400] loss: 0.0101032\n",
            "[154,   500] loss: 0.0101675\n",
            "[154,   600] loss: 0.0101620\n",
            "        |==>  acc: 0.8491,  nmi: 0.7750  <==|\n",
            "[155,   100] loss: 0.0100560\n",
            "[155,   200] loss: 0.0100170\n",
            "[155,   300] loss: 0.0100332\n",
            "[155,   400] loss: 0.0101784\n",
            "[155,   500] loss: 0.0100875\n",
            "[155,   600] loss: 0.0101786\n",
            "        |==>  acc: 0.8462,  nmi: 0.7721  <==|\n",
            "[156,   100] loss: 0.0100192\n",
            "[156,   200] loss: 0.0100753\n",
            "[156,   300] loss: 0.0100247\n",
            "[156,   400] loss: 0.0101804\n",
            "[156,   500] loss: 0.0100678\n",
            "[156,   600] loss: 0.0101435\n",
            "        |==>  acc: 0.8483,  nmi: 0.7736  <==|\n",
            "[157,   100] loss: 0.0100336\n",
            "[157,   200] loss: 0.0100413\n",
            "[157,   300] loss: 0.0100909\n",
            "[157,   400] loss: 0.0101213\n",
            "[157,   500] loss: 0.0100607\n",
            "[157,   600] loss: 0.0100746\n",
            "        |==>  acc: 0.8508,  nmi: 0.7761  <==|\n",
            "[158,   100] loss: 0.0099363\n",
            "[158,   200] loss: 0.0100501\n",
            "[158,   300] loss: 0.0100665\n",
            "[158,   400] loss: 0.0101065\n",
            "[158,   500] loss: 0.0100662\n",
            "[158,   600] loss: 0.0101113\n",
            "        |==>  acc: 0.8508,  nmi: 0.7747  <==|\n",
            "[159,   100] loss: 0.0099757\n",
            "[159,   200] loss: 0.0099642\n",
            "[159,   300] loss: 0.0100214\n",
            "[159,   400] loss: 0.0101071\n",
            "[159,   500] loss: 0.0100732\n",
            "[159,   600] loss: 0.0101223\n",
            "        |==>  acc: 0.8487,  nmi: 0.7755  <==|\n",
            "[160,   100] loss: 0.0100301\n",
            "[160,   200] loss: 0.0099774\n",
            "[160,   300] loss: 0.0100798\n",
            "[160,   400] loss: 0.0101189\n",
            "[160,   500] loss: 0.0100545\n",
            "[160,   600] loss: 0.0100396\n",
            "        |==>  acc: 0.8439,  nmi: 0.7708  <==|\n",
            "[161,   100] loss: 0.0099905\n",
            "[161,   200] loss: 0.0100010\n",
            "[161,   300] loss: 0.0100657\n",
            "[161,   400] loss: 0.0100322\n",
            "[161,   500] loss: 0.0100432\n",
            "[161,   600] loss: 0.0100341\n",
            "        |==>  acc: 0.8459,  nmi: 0.7721  <==|\n",
            "[162,   100] loss: 0.0100578\n",
            "[162,   200] loss: 0.0100296\n",
            "[162,   300] loss: 0.0100212\n",
            "[162,   400] loss: 0.0100987\n",
            "[162,   500] loss: 0.0099190\n",
            "[162,   600] loss: 0.0099490\n",
            "        |==>  acc: 0.8472,  nmi: 0.7733  <==|\n",
            "[163,   100] loss: 0.0099867\n",
            "[163,   200] loss: 0.0099865\n",
            "[163,   300] loss: 0.0100073\n",
            "[163,   400] loss: 0.0099528\n",
            "[163,   500] loss: 0.0100364\n",
            "[163,   600] loss: 0.0100635\n",
            "        |==>  acc: 0.8497,  nmi: 0.7767  <==|\n",
            "[164,   100] loss: 0.0099183\n",
            "[164,   200] loss: 0.0099888\n",
            "[164,   300] loss: 0.0099621\n",
            "[164,   400] loss: 0.0100181\n",
            "[164,   500] loss: 0.0100553\n",
            "[164,   600] loss: 0.0100557\n",
            "        |==>  acc: 0.8515,  nmi: 0.7756  <==|\n",
            "[165,   100] loss: 0.0099561\n",
            "[165,   200] loss: 0.0100304\n",
            "[165,   300] loss: 0.0099611\n",
            "[165,   400] loss: 0.0099957\n",
            "[165,   500] loss: 0.0099634\n",
            "[165,   600] loss: 0.0099955\n",
            "        |==>  acc: 0.8483,  nmi: 0.7746  <==|\n",
            "[166,   100] loss: 0.0099731\n",
            "[166,   200] loss: 0.0099696\n",
            "[166,   300] loss: 0.0098897\n",
            "[166,   400] loss: 0.0100085\n",
            "[166,   500] loss: 0.0099557\n",
            "[166,   600] loss: 0.0099962\n",
            "        |==>  acc: 0.8507,  nmi: 0.7775  <==|\n",
            "[167,   100] loss: 0.0098901\n",
            "[167,   200] loss: 0.0099335\n",
            "[167,   300] loss: 0.0099872\n",
            "[167,   400] loss: 0.0099721\n",
            "[167,   500] loss: 0.0099505\n",
            "[167,   600] loss: 0.0100459\n",
            "        |==>  acc: 0.8484,  nmi: 0.7741  <==|\n",
            "[168,   100] loss: 0.0098808\n",
            "[168,   200] loss: 0.0098797\n",
            "[168,   300] loss: 0.0099544\n",
            "[168,   400] loss: 0.0100589\n",
            "[168,   500] loss: 0.0099200\n",
            "[168,   600] loss: 0.0099861\n",
            "        |==>  acc: 0.8506,  nmi: 0.7783  <==|\n",
            "[169,   100] loss: 0.0097875\n",
            "[169,   200] loss: 0.0099593\n",
            "[169,   300] loss: 0.0099754\n",
            "[169,   400] loss: 0.0099527\n",
            "[169,   500] loss: 0.0099561\n",
            "[169,   600] loss: 0.0099703\n",
            "        |==>  acc: 0.8536,  nmi: 0.7758  <==|\n",
            "[170,   100] loss: 0.0098756\n",
            "[170,   200] loss: 0.0099388\n",
            "[170,   300] loss: 0.0099333\n",
            "[170,   400] loss: 0.0099447\n",
            "[170,   500] loss: 0.0099157\n",
            "[170,   600] loss: 0.0099412\n",
            "        |==>  acc: 0.8477,  nmi: 0.7740  <==|\n",
            "[171,   100] loss: 0.0099238\n",
            "[171,   200] loss: 0.0098121\n",
            "[171,   300] loss: 0.0098817\n",
            "[171,   400] loss: 0.0099418\n",
            "[171,   500] loss: 0.0100123\n",
            "[171,   600] loss: 0.0099034\n",
            "        |==>  acc: 0.8503,  nmi: 0.7785  <==|\n",
            "[172,   100] loss: 0.0098298\n",
            "[172,   200] loss: 0.0099040\n",
            "[172,   300] loss: 0.0098964\n",
            "[172,   400] loss: 0.0098657\n",
            "[172,   500] loss: 0.0099531\n",
            "[172,   600] loss: 0.0099674\n",
            "        |==>  acc: 0.8520,  nmi: 0.7786  <==|\n",
            "[173,   100] loss: 0.0098258\n",
            "[173,   200] loss: 0.0099062\n",
            "[173,   300] loss: 0.0098875\n",
            "[173,   400] loss: 0.0098234\n",
            "[173,   500] loss: 0.0099687\n",
            "[173,   600] loss: 0.0099634\n",
            "        |==>  acc: 0.8501,  nmi: 0.7775  <==|\n",
            "[174,   100] loss: 0.0098126\n",
            "[174,   200] loss: 0.0099162\n",
            "[174,   300] loss: 0.0098260\n",
            "[174,   400] loss: 0.0099173\n",
            "[174,   500] loss: 0.0098402\n",
            "[174,   600] loss: 0.0099754\n",
            "        |==>  acc: 0.8503,  nmi: 0.7743  <==|\n",
            "[175,   100] loss: 0.0098298\n",
            "[175,   200] loss: 0.0098589\n",
            "[175,   300] loss: 0.0098029\n",
            "[175,   400] loss: 0.0098860\n",
            "[175,   500] loss: 0.0099307\n",
            "[175,   600] loss: 0.0099351\n",
            "        |==>  acc: 0.8495,  nmi: 0.7761  <==|\n",
            "[176,   100] loss: 0.0098104\n",
            "[176,   200] loss: 0.0098966\n",
            "[176,   300] loss: 0.0098368\n",
            "[176,   400] loss: 0.0098378\n",
            "[176,   500] loss: 0.0099539\n",
            "[176,   600] loss: 0.0098628\n",
            "        |==>  acc: 0.8511,  nmi: 0.7776  <==|\n",
            "[177,   100] loss: 0.0097627\n",
            "[177,   200] loss: 0.0099118\n",
            "[177,   300] loss: 0.0098549\n",
            "[177,   400] loss: 0.0098833\n",
            "[177,   500] loss: 0.0098222\n",
            "[177,   600] loss: 0.0098936\n",
            "        |==>  acc: 0.8572,  nmi: 0.7797  <==|\n",
            "[178,   100] loss: 0.0097287\n",
            "[178,   200] loss: 0.0098704\n",
            "[178,   300] loss: 0.0097393\n",
            "[178,   400] loss: 0.0099001\n",
            "[178,   500] loss: 0.0098351\n",
            "[178,   600] loss: 0.0099534\n",
            "        |==>  acc: 0.8487,  nmi: 0.7775  <==|\n",
            "[179,   100] loss: 0.0097284\n",
            "[179,   200] loss: 0.0097967\n",
            "[179,   300] loss: 0.0098891\n",
            "[179,   400] loss: 0.0097938\n",
            "[179,   500] loss: 0.0098754\n",
            "[179,   600] loss: 0.0099009\n",
            "        |==>  acc: 0.8562,  nmi: 0.7811  <==|\n",
            "[180,   100] loss: 0.0097982\n",
            "[180,   200] loss: 0.0098182\n",
            "[180,   300] loss: 0.0097697\n",
            "[180,   400] loss: 0.0098197\n",
            "[180,   500] loss: 0.0098659\n",
            "[180,   600] loss: 0.0098704\n",
            "        |==>  acc: 0.8516,  nmi: 0.7797  <==|\n",
            "[181,   100] loss: 0.0097408\n",
            "[181,   200] loss: 0.0097772\n",
            "[181,   300] loss: 0.0098015\n",
            "[181,   400] loss: 0.0097542\n",
            "[181,   500] loss: 0.0099067\n",
            "[181,   600] loss: 0.0098468\n",
            "        |==>  acc: 0.8528,  nmi: 0.7779  <==|\n",
            "[182,   100] loss: 0.0096830\n",
            "[182,   200] loss: 0.0097901\n",
            "[182,   300] loss: 0.0097557\n",
            "[182,   400] loss: 0.0097968\n",
            "[182,   500] loss: 0.0098844\n",
            "[182,   600] loss: 0.0098520\n",
            "        |==>  acc: 0.8490,  nmi: 0.7753  <==|\n",
            "[183,   100] loss: 0.0097177\n",
            "[183,   200] loss: 0.0097556\n",
            "[183,   300] loss: 0.0098130\n",
            "[183,   400] loss: 0.0097325\n",
            "[183,   500] loss: 0.0098542\n",
            "[183,   600] loss: 0.0098118\n",
            "        |==>  acc: 0.8514,  nmi: 0.7790  <==|\n",
            "[184,   100] loss: 0.0097277\n",
            "[184,   200] loss: 0.0097128\n",
            "[184,   300] loss: 0.0096923\n",
            "[184,   400] loss: 0.0098195\n",
            "[184,   500] loss: 0.0098538\n",
            "[184,   600] loss: 0.0098848\n",
            "        |==>  acc: 0.8527,  nmi: 0.7773  <==|\n",
            "[185,   100] loss: 0.0097449\n",
            "[185,   200] loss: 0.0096968\n",
            "[185,   300] loss: 0.0098296\n",
            "[185,   400] loss: 0.0097744\n",
            "[185,   500] loss: 0.0097518\n",
            "[185,   600] loss: 0.0097951\n",
            "        |==>  acc: 0.8545,  nmi: 0.7800  <==|\n",
            "[186,   100] loss: 0.0096793\n",
            "[186,   200] loss: 0.0096997\n",
            "[186,   300] loss: 0.0098420\n",
            "[186,   400] loss: 0.0098231\n",
            "[186,   500] loss: 0.0097853\n",
            "[186,   600] loss: 0.0097755\n",
            "        |==>  acc: 0.8561,  nmi: 0.7840  <==|\n",
            "[187,   100] loss: 0.0097420\n",
            "[187,   200] loss: 0.0098706\n",
            "[187,   300] loss: 0.0097288\n",
            "[187,   400] loss: 0.0097897\n",
            "[187,   500] loss: 0.0097278\n",
            "[187,   600] loss: 0.0096874\n",
            "        |==>  acc: 0.8513,  nmi: 0.7791  <==|\n",
            "[188,   100] loss: 0.0096931\n",
            "[188,   200] loss: 0.0097601\n",
            "[188,   300] loss: 0.0097784\n",
            "[188,   400] loss: 0.0096975\n",
            "[188,   500] loss: 0.0097324\n",
            "[188,   600] loss: 0.0097145\n",
            "        |==>  acc: 0.8471,  nmi: 0.7748  <==|\n",
            "[189,   100] loss: 0.0096204\n",
            "[189,   200] loss: 0.0096790\n",
            "[189,   300] loss: 0.0097510\n",
            "[189,   400] loss: 0.0097057\n",
            "[189,   500] loss: 0.0098091\n",
            "[189,   600] loss: 0.0098376\n",
            "        |==>  acc: 0.8509,  nmi: 0.7776  <==|\n",
            "[190,   100] loss: 0.0095433\n",
            "[190,   200] loss: 0.0096968\n",
            "[190,   300] loss: 0.0097310\n",
            "[190,   400] loss: 0.0097954\n",
            "[190,   500] loss: 0.0097231\n",
            "[190,   600] loss: 0.0098153\n",
            "        |==>  acc: 0.8493,  nmi: 0.7756  <==|\n",
            "[191,   100] loss: 0.0097061\n",
            "[191,   200] loss: 0.0096926\n",
            "[191,   300] loss: 0.0098259\n",
            "[191,   400] loss: 0.0096145\n",
            "[191,   500] loss: 0.0097201\n",
            "[191,   600] loss: 0.0097256\n",
            "        |==>  acc: 0.8523,  nmi: 0.7791  <==|\n",
            "[192,   100] loss: 0.0096896\n",
            "[192,   200] loss: 0.0097345\n",
            "[192,   300] loss: 0.0097036\n",
            "[192,   400] loss: 0.0097025\n",
            "[192,   500] loss: 0.0096986\n",
            "[192,   600] loss: 0.0097197\n",
            "        |==>  acc: 0.8529,  nmi: 0.7794  <==|\n",
            "[193,   100] loss: 0.0096000\n",
            "[193,   200] loss: 0.0096923\n",
            "[193,   300] loss: 0.0096821\n",
            "[193,   400] loss: 0.0097628\n",
            "[193,   500] loss: 0.0097083\n",
            "[193,   600] loss: 0.0097246\n",
            "        |==>  acc: 0.8504,  nmi: 0.7777  <==|\n",
            "[194,   100] loss: 0.0096481\n",
            "[194,   200] loss: 0.0096610\n",
            "[194,   300] loss: 0.0096782\n",
            "[194,   400] loss: 0.0097375\n",
            "[194,   500] loss: 0.0096769\n",
            "[194,   600] loss: 0.0096798\n",
            "        |==>  acc: 0.8507,  nmi: 0.7781  <==|\n",
            "[195,   100] loss: 0.0096452\n",
            "[195,   200] loss: 0.0096585\n",
            "[195,   300] loss: 0.0095618\n",
            "[195,   400] loss: 0.0096567\n",
            "[195,   500] loss: 0.0097044\n",
            "[195,   600] loss: 0.0097946\n",
            "        |==>  acc: 0.8509,  nmi: 0.7773  <==|\n",
            "[196,   100] loss: 0.0095288\n",
            "[196,   200] loss: 0.0096372\n",
            "[196,   300] loss: 0.0097450\n",
            "[196,   400] loss: 0.0096947\n",
            "[196,   500] loss: 0.0096727\n",
            "[196,   600] loss: 0.0097096\n",
            "        |==>  acc: 0.8502,  nmi: 0.7765  <==|\n",
            "[197,   100] loss: 0.0096121\n",
            "[197,   200] loss: 0.0095641\n",
            "[197,   300] loss: 0.0097526\n",
            "[197,   400] loss: 0.0096201\n",
            "[197,   500] loss: 0.0096394\n",
            "[197,   600] loss: 0.0097574\n",
            "        |==>  acc: 0.8529,  nmi: 0.7791  <==|\n",
            "[198,   100] loss: 0.0095994\n",
            "[198,   200] loss: 0.0097132\n",
            "[198,   300] loss: 0.0096512\n",
            "[198,   400] loss: 0.0096520\n",
            "[198,   500] loss: 0.0096110\n",
            "[198,   600] loss: 0.0096821\n",
            "        |==>  acc: 0.8512,  nmi: 0.7776  <==|\n",
            "[199,   100] loss: 0.0095329\n",
            "[199,   200] loss: 0.0096057\n",
            "[199,   300] loss: 0.0096661\n",
            "[199,   400] loss: 0.0096677\n",
            "[199,   500] loss: 0.0096454\n",
            "[199,   600] loss: 0.0096893\n",
            "        |==>  acc: 0.8524,  nmi: 0.7793  <==|\n",
            "[200,   100] loss: 0.0095732\n",
            "[200,   200] loss: 0.0096461\n",
            "[200,   300] loss: 0.0096447\n",
            "[200,   400] loss: 0.0095998\n",
            "[200,   500] loss: 0.0095921\n",
            "[200,   600] loss: 0.0097123\n",
            "        |==>  acc: 0.8521,  nmi: 0.7795  <==|\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fMgxNNFLmUYq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}